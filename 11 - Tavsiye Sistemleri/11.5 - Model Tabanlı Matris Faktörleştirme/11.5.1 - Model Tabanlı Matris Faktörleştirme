KONU: Model Tabanlı Matris Faktörleştirme (Model-Based Matrix Factorization)
TÜR: Kapsamlı Alt Konular, Teknik Detaylar ve Örnekler

GİRİŞ
Model tabanlı matris faktörleştirme, kullanıcılar ve ürünler arasındaki ilişkileri "gizli öznitelikler" (latent factors) üzerinden açıklamaya çalışan, modern öneri sistemlerinin en temel yapı taşıdır.

================================================================================
1. TEMEL MANTIK VE GİZLİ ÖZNİTELİKLER (LATENT FACTORS)
================================================================================
Bu yaklaşım, kullanıcıları ve ürünleri (film, kitap, ürün vb.) aynı "gizli" uzayda vektörler olarak temsil eder.

A. Kavram
Büyük bir "Kullanıcı x Ürün" matrisini, iki küçük matrisin çarpımı olarak yazarız:
1. Kullanıcı Matrisi (P): Kullanıcının özelliklere ilgisi.
2. Ürün Matrisi (Q): Ürünün sahip olduğu özellikler.

B. Matematiksel Temel
Tahmini Puan (r_hat) = (Kullanıcı Vektörü) . (Ürün Vektörü)
Formül: r_ui = q_i^T * p_u

C. Örnek Senaryo
Senaryo: Bir film platformu.
Gizli Özellikler: [Aksiyon, Romantik, Bilim Kurgu]

- Kullanıcı (Ali): Aksiyon sever, Romantik sevmez.
  Ali'nin Vektörü: [0.9, 0.1, 0.5]

- Film A (Hızlı ve Öfkeli): Tam aksiyon filmi.
  Film A Vektörü:  [0.95, 0.05, 0.2]

- Film B (Not Defteri): Tam romantik film.
  Film B Vektörü:  [0.05, 0.95, 0.1]

Hesaplama:
Ali'nin Film A puanı: (0.9*0.95) + (0.1*0.05) + (0.5*0.2) = 0.96 (Yüksek Puan -> Önerilir)
Ali'nin Film B puanı: (0.9*0.05) + (0.1*0.95) + (0.5*0.1) = 0.19 (Düşük Puan -> Önerilmez)

================================================================================
2. BAŞLICA ALGORİTMALAR
================================================================================

A. Tekil Değer Ayrışımı (SVD - Singular Value Decomposition)
- Tanım: Matrisi U, Sigma ve V olarak üç bileşene ayırır.
- Kullanım: Genellikle veri setindeki gürültüyü azaltmak ve boyut indirgemek için kullanılır.
- Sorun: Eksik verilerin (missing values) olduğu matrislerde (ki öneri sistemleri genelde böyledir) klasik SVD çalışmaz. Bunun yerine "Funk SVD" gibi varyasyonlar kullanılır.

B. Negatif Olmayan Matris Faktörleştirme (NMF - Non-negative Matrix Factorization)
- Tanım: Matris bileşenlerinin negatif olmamasını şart koşar.
- Neden Önemli?: Gerçek hayatta "-5 tane kitap okudum" gibi bir veri olmadığı için, sonuçların daha yorumlanabilir olmasını sağlar (Örn: Bir film %30 Aksiyon, %70 Komedi içerir).
- Kullanım: Görüntü işleme ve metin madenciliğinde de sıkça kullanılır.

C. SVD++ (Implicit Feedback Dahil Etme)
- Tanım: Klasik SVD sadece verilen puanları (Explicit) kullanır. SVD++, kullanıcının site içi davranışlarını (tıklama, sepete atma vb.) da denkleme ekler.
- Mantık: "Puan vermediyse bile o ürüne tıkladıysa bir ilgisi vardır" mantığıyla çalışır.

================================================================================
3. OPTİMİZASYON YÖNTEMLERİ (MODEL NASIL ÖĞRENİR?)
================================================================================
Modelin amacı, tahmin edilen puan ile gerçek puan arasındaki hatayı (Loss Function) en aza indirmektir.

A. Stokastik Gradyan İnişi (SGD - Stochastic Gradient Descent)
- Çalışma Prensibi: Her bir puanlama verisi için hatayı hesaplar ve parametreleri o an günceller.
- Avantajı: Çok hızlıdır ve kolay uygulanır.
- Örnek: Model tahmini 3, Gerçek puan 5 -> Hata +2. Bu hatayı kullanarak kullanıcının ve filmin vektörlerini biraz yukarı çeker.

B. Alternatif En Küçük Kareler (ALS - Alternating Least Squares)
- Çalışma Prensibi: Önce kullanıcı vektörlerini sabit tutup ürünleri günceller, sonra ürünleri sabit tutup kullanıcıları günceller. Zig-zag çizerek ilerler.
- Avantajı: Paralelleştirilebilir (Büyük veri setlerinde, Spark gibi sistemlerde harika çalışır).
- Uygunluk: "Implicit Feedback" (Örtük veri) veri setlerinde daha kararlıdır.

================================================================================
4. DÜZENLİLEŞTİRME (REGULARIZATION)
================================================================================
Modelin veriyi ezberlemesini (Overfitting) engellemek için kullanılır.

- Amaç: Modelin uçuk katsayılar üretmesini engeller.
- Yöntem: Hata fonksiyonuna bir ceza terimi (Lambda) eklenir. Bu, modelin "sadece veriye uyma, aynı zamanda vektör değerlerini küçük ve basit tut" demesini sağlar.

================================================================================
5. YANLILIK TERİMLERİ (BIAS TERMS)
================================================================================
Sadece kullanıcı ve ürün etkileşimi her zaman yeterli değildir. Bazı dış faktörler eklenmelidir.

1. Global Ortalama (Mu): Tüm filmlerin genel puan ortalaması.
2. Kullanıcı Yanlılığı (b_u): Bazı kullanıcılar her şeye 5 verir, bazıları en fazla 3 verir. Bu kişisel bir sapmadır.
3. Ürün Yanlılığı (b_i): Titanic filmi, kim izlerse izlesin ortalamanın üstünde puan alma eğilimindedir.

Gelişmiş Formül:
Tahmin = Global_Ort + Kullanıcı_Sapması + Ürün_Sapması + (Kullanıcı . Ürün)

================================================================================
ÖZET KARŞILAŞTIRMA TABLOSU
================================================================================
YÖNTEM      | EN İYİ KULLANIM       | AVANTAJ
----------- | --------------------- | -----------------------
Funk SVD    | Film Puanlama (Netflix)| Yüksek doğruluk
ALS         | Büyük Veri & Örtük Veri| Paralel çalışabilme hızı
NMF         | Metin/Görüntü Analizi | Yorumlanabilir sonuçlar