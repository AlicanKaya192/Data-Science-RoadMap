BAŞLIK: LOJİSTİK REGRESYON (LOGISTIC REGRESSION)
TÜR: Sınıflandırma Algoritması ve Olasılık Tahmini

================================================================================
1. GİRİŞ: İSMİNDEKİ TUZAK
================================================================================
Lojistik Regresyon, isminde "Regresyon" geçse de, Makine Öğrenmesinde bir SINIFLANDIRMA algoritması olarak kullanılır.

- Doğrusal Regresyon: "Evin fiyatı 500.000 TL" der (Sayı tahmin eder).
- Lojistik Regresyon: "Bu e-posta %95 ihtimalle Spam'dir" der (Kategori/Olasılık tahmin eder).

Temel Amaç: Girdileri (X) alıp, sonucun belirli bir sınıfa (0 veya 1) ait olma OLASILIĞINI hesaplamaktır.

================================================================================
2. NEDEN DOĞRUSAL REGRESYON KULLANMIYORUZ?
================================================================================
Sınıflandırma için düz çizgi (Linear Regression) çizersek iki sorun olur:
1. Sınır Aşımı: Doğrusal model eksi sonsuz ile artı sonsuz arasında değer üretir. Ancak olasılık 0 ile 1 arasında olmalıdır. "Bu tümör %150 kanserli" veya "%-20 kanserli" diyemeyiz.
2. Hassasiyet: Uç değerler (Outliers), doğrunun eğimini bozar ve sınıflandırma eşiğini kaydırır.

Çözüm: Çıktıyı 0 ile 1 arasına "sıkıştıran" bir fonksiyona ihtiyacımız vardır.

================================================================================
3. SİGMOİD FONKSİYONU (AKTİVASYON)
================================================================================
Lojistik Regresyonun kalbidir. Doğrusal formülden gelen sonucu (z = wx+b) alır ve büker.

- Şekli: "S" harfine benzer.
- Matematiksel Formül:
  σ(z) = 1 / (1 + e^(-z))

Nasıl Çalışır?
- Girdi (z) çok büyük pozitif bir sayıysa -> Sonuç 1'e yaklaşır.
- Girdi (z) çok küçük negatif bir sayıysa -> Sonuç 0'a yaklaşır.
- Girdi (z) 0 ise -> Sonuç tam 0.5 olur.

Böylece modelin çıktısı her zaman [0, 1] aralığında bir olasılık değeri olur.

================================================================================
4. TAHMİN MEKANİZMASI VE KARAR SINIRI (DECISION BOUNDARY)
================================================================================
Model bir olasılık üretir (Örn: 0.8). Peki buna "Evet" mi diyeceğiz "Hayır" mı?

Bir Eşik Değeri (Threshold) belirlenir (Genellikle 0.5).

- Tahmin ≥ 0.5 ise -> Sınıf 1 (Pozitif / Hasta / Spam)
- Tahmin < 0.5 ise -> Sınıf 0 (Negatif / Sağlıklı / Normal)

Örnek:
Modelin çıktısı 0.7 çıktı. Eşik 0.5 olduğu için "Sınıf 1" olarak etiketlenir.
(Not: Bu eşik değeri probleme göre değiştirilebilir. Hassas bir tıbbi testte eşiği 0.3'e çekip daha fazla kişiye "Riskli" diyebilirsiniz).

================================================================================
5. MALİYET FONKSİYONU: LOG LOSS (BINARY CROSS ENTROPY)
================================================================================
Doğrusal Regresyonda "Hataların Karesini" (MSE) alıyorduk. Lojistik Regresyonda bunu yapamayız.
Neden? Çünkü Sigmoid fonksiyonu işin içine girince, hata grafiği "Dışbükey" (Convex - Kase şeklinde) olmaz. Dalgalı olur ve Gradyan İniş algoritması yanlış çukurlara (Local Minima) takılır.

Çözüm: "Log Loss" (Logaritmik Kayıp) fonksiyonu kullanılır.

Formül Mantığı:
Amaç, yanlış tahminleri logaritmik olarak (çok sert) cezalandırmaktır.

- Durum A (Gerçek = 1):
  Model 0.9 tahmin ederse -> Ceza çok az (log(0.9) ≈ 0).
  Model 0.1 tahmin ederse -> Ceza DEVASA (log(0.1)). Çünkü model emin bir şekilde yanlış yapmıştır.

- Durum B (Gerçek = 0):
  Tam tersi geçerlidir.

Bu fonksiyon sayesinde hata grafiği tekrar pürüzsüz bir "Kase" şekline döner ve global minimum rahatça bulunur.

================================================================================
6. ÇOKLU SINIFLANDIRMA (MULTICLASS CLASSIFICATION)
================================================================================
Lojistik regresyon temelde İkili (Binary) sınıflandırma (0/1) içindir. Peki ya "Kedi/Köpek/Kuş" gibi 3 sınıf varsa?

Yöntem 1: One-vs-Rest (OvR)
- Her sınıf için ayrı bir model eğitilir.
  1. Model: Kedi mi? (Evet/Hayır)
  2. Model: Köpek mi? (Evet/Hayır)
  3. Model: Kuş mu? (Evet/Hayır)
- Hangi model en yüksek olasılığı verirse o seçilir.

Yöntem 2: Softmax Regresyon (Multinomial)
- Sigmoid yerine "Softmax" fonksiyonu kullanılır. Bu fonksiyon, tüm sınıfların olasılıkları toplamının 1 olmasını sağlar (Örn: Kedi %70, Köpek %20, Kuş %10).

================================================================================
7. AVANTAJLAR VE DEZAVANTAJLAR
================================================================================

AVANTAJLAR:
- Basit ve Hızlı: Eğitimi ve tahmini çok hızlıdır.
- Olasılık Verir: Sadece "Kanser" demez, "%85 ihtimalle Kanser" der. Bu bilgi kritiktir.
- Yorumlanabilir: Hangi özelliğin (Örn: Sigara içmek) sonucu ne kadar etkilediği (Ağırlıklar) net görülür.

DEZAVANTAJLAR:
- Doğrusal Sınır: Verileri ayırmak için sadece düz bir çizgi (veya düzlem) çizebilir. Eğer veriler iç içe geçmişse (dairesel vb.) başarısız olur.
- Varsayımlar: Özelliklerin birbirinden bağımsız olduğunu varsayar.

================================================================================
ÖZET KARŞILAŞTIRMA
================================================================================
ÖZELLİK             | DOĞRUSAL REGRESYON        | LOJİSTİK REGRESYON
------------------- | ------------------------- | --------------------------
Hedef Değişken (y)  | Sürekli Sayı (Fiyat)      | Kategorik (Evet/Hayır)
Kullanılan Fonksiyon| Doğrusal (y=wx+b)         | Sigmoid (S Eğrisi)
Maliyet Fonksiyonu  | MSE (Kare Hata)           | Log Loss (Cross Entropy)
Çıktı Aralığı       | -Sonsuz ile +Sonsuz       | 0 ile 1 arası