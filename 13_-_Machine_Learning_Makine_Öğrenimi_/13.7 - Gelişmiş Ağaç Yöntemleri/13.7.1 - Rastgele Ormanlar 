BAŞLIK: RASTGELE ORMANLAR (RANDOM FOREST) - KAPSAMLI REHBER
TÜR: Topluluk Öğrenmesi (Ensemble Learning), Bagging Algoritması

================================================================================
1. GİRİŞ: NEDEN TEK AĞAÇ YETMEDİ?
================================================================================
Önceki dosyada (CART) gördüğümüz gibi, Tekil Karar Ağaçlarının en büyük hastalığı "Yüksek Varyans"tır. Yani eğitim verisini aşırı ezberlerler. Verideki küçücük bir gürültüyü bile kural zannederler.

Rastgele Orman Mantığı:
"Bir bilene sormaktansa, bin kişiye sorup ortak kararı almak daha iyidir."

Rastgele Orman, yüzlerce karar ağacını eğitir ve sonucu bunların oylamasına sunar.
- Hata Yapma Olasılığı: Tek bir ağacın hata yapma ihtimali yüksektir.
- Kolektif Başarı: Birbirinden farklı 100 ağacın aynı anda, aynı noktada hata yapma ihtimali çok düşüktür.

================================================================================
2. TEMEL MEKANİZMA: BAGGING VE FEATURE RANDOMNESS
================================================================================
Random Forest'ı "Random" (Rastgele) yapan iki kritik özellik vardır. Bu özellikler, ormandaki ağaçların birbirinin kopyası olmasını engeller (De-correlation).

A. BAGGING (BOOTSTRAP AGGREGATING) - SATIR RASTGELELİĞİ
Her ağaca verinin tamamını göstermeyiz. Her ağaç için veriden rastgele seçim yaparız.

- Yöntem: "İadeli Seçim" (Sampling with Replacement).
- Örnek: Veri setimiz [A, B, C, D] olsun.
  * 1. Ağaç için çanta: [A, B, A, C] (D seçilmedi, A iki kere seçildi).
  * 2. Ağaç için çanta: [B, D, D, C].
- Sonuç: Her ağaç verinin farklı bir alt kümesini görerek uzmanlaşır.

B. FEATURE RANDOMNESS - SÜTUN RASTGELELİĞİ (KRİTİK FARK)
Bu, Random Forest'ı normal Bagging yönteminden ayıran en önemli özelliktir.
Bir ağaç soru sorarken (bölünme yaparken), elindeki TÜM değişkenlere bakamaz.

- Kural: Her düğümde, toplam değişken sayısının karekökü kadar (genelde sqrt(p)) rastgele değişken seçilir ve en iyi soru SADECE bunlar arasından aranır.
- Neden? Eğer çok baskın bir özellik varsa (Örn: "Gelir"), bütün ağaçlar ilk soruyu "Gelir" üzerinden sorar ve hepsi birbirine benzer. Biz ağaçların farklı düşünmesini istiyoruz.

================================================================================
3. ALGORİTMA ADIMLARI (ADIM ADIM ÇALIŞMA)
================================================================================

1. Hazırlık:
   Kullanıcı "Bana 100 ağaçlık bir orman kur" der (n_estimators=100).

2. Bootstrap Döngüsü (Her ağaç için):
   Orijinal veriden rastgele örneklem alarak yeni bir mini veri seti oluştur.

3. Ağaç Büyütme (Grow):
   Bu mini veri setiyle bir Karar Ağacı başlat. Ancak her düğümde:
   - Rastgele 'k' adet özellik seç.
   - Sadece bu 'k' özellik içindeki en iyi Gini/Bilgi Kazancı sağlayan soruyu bul.
   - Böl ve devam et (Budama yapmadan sonuna kadar büyütülür).

4. Tahmin (Prediction):
   Yeni bir veri geldiğinde 100 ağacın hepsine sorulur.
   - Sınıflandırma: 100 ağacın oyları sayılır. En çok oy alan sınıf kazanır (Majority Vote).
   - Regresyon: 100 ağacın tahmin ettiği sayıların ortalaması alınır.

================================================================================
4. SAYISAL SENARYO: "BU MÜŞTERİ KREDİYİ ÖDER Mİ?"
================================================================================
Elimizde 3 Ağaçlık minik bir orman olsun.
Müşteri: {Gelir: Orta, Yaş: Genç, Eğitim: Yüksek}

Ağaç 1 (Eğitim verisinin %60'ını gördü, "Yaş"a odaklandı):
- Karar: ÖDEMEZ (Riskli buldu).

Ağaç 2 (Eğitim verisinin farklı %60'ını gördü, "Eğitim"e odaklandı):
- Karar: ÖDER (Eğitimli olduğu için güvendi).

Ağaç 3 (Farklı bir veri grubu gördü, "Gelir"e odaklandı):
- Karar: ÖDER.

SONUÇ (ENSEMBLE):
- Oylar: 2 ÖDER vs 1 ÖDEMEZ.
- Final Kararı: KREDİ VERİLSİN.
*Not: Tek başına 1. ağaca kalsaydık müşteriyi kaybedecektik. Çoğunluk doğru yolu buldu.*

================================================================================
5. OOB (OUT-OF-BAG) ERROR: BEDAVA DOĞRULAMA
================================================================================
Bootstrap yaparken (A Bölümü), her ağaç için verilerin yaklaşık 1/3'ü torbaya girmez. Bu verilere "Out-of-Bag" (Çanta Dışı) veri denir.

- Fırsat: Model eğitilirken hiç görmediği bu 1/3'lük veriyi test seti gibi kullanabiliriz.
- Avantaj: Random Forest kullanırken ayrıca bir "Validation Set" ayırmaya gerek yoktur. OOB Score bize modelin başarısını söyler.

================================================================================
6. DEĞİŞKEN ÖNEM DÜZEYLERİ (FEATURE IMPORTANCE)
================================================================================
Random Forest, "Hangi değişken sonucu en çok etkiliyor?" sorusuna harika cevap verir.

Hesaplama Mantığı:
- "Gelir" değişkeni kullanılarak yapılan bölünmelerde, Gini Safsızlığı toplamda ne kadar düştü?
- Eğer "Gelir" değişkeni ağaçlarda tepe noktalarda kullanılıyor ve Gini'yi çok düşürüyorsa, bu değişken önemlidir.
- Sonuçta size şöyle bir liste verir:
  1. Gelir (%45)
  2. Kredi Notu (%30)
  3. Yaş (%5) ...

================================================================================
7. AVANTAJLAR VE DEZAVANTAJLAR
================================================================================

AVANTAJLAR:
1. Yüksek Doğruluk: Genellikle tek ağaçtan çok daha başarılıdır.
2. Overfitting Direnci: Çok sayıda ağaç olduğu için ezberleme riski düşüktür.
3. Ayar Gerektirmez: Hiçbir parametreye dokunmasanız bile (default) gayet iyi çalışır.
4. Veri Tipi: Hem sayısal hem kategorik veriyle uğraşabilir, ölçekleme (scaling) istemez.

DEZAVANTAJLAR:
1. Kara Kutu (Black Box): 1000 tane ağacın içini tek tek inceleyip "Neden bu kararı verdi?" demek zordur. Yorumlanabilirliği düşüktür.
2. Yavaş Tahmin: Canlı sistemlerde (Real-time), tek bir ağaca göre daha yavaştır çünkü veriyi 100 ağaçtan geçirmesi gerekir.
3. Model Boyutu: Yüzlerce ağacı hafızada tutmak RAM tüketir.

================================================================================
ÖZET TABLO: CART vs RANDOM FOREST
================================================================================
ÖZELLİK             | CART (TEK AĞAÇ)           | RANDOM FOREST (ORMAN)
------------------- | ------------------------- | ------------------------------
Çalışma Prensibi    | Böl ve Yönet              | Topluluk (Ensemble) & Oylama
Varyans (Hata)      | Yüksek (Ezberler)         | Düşük (Dengeler)
Yorumlanabilirlik   | Çok Yüksek (Görselleşir)  | Düşük (Karmaşık yapı)
Hız (Eğitim)        | Çok Hızlı                 | Yavaş (N kat daha fazla işlem)
Hız (Tahmin)        | Anlık                     | Görece Yavaş
Parametre Ayarı     | Hassas (Budama gerekir)   | Sağlam (Ayarsız da çalışır)