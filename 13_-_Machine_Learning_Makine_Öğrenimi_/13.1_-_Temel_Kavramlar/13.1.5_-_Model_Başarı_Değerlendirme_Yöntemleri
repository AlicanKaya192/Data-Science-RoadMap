BAŞLIK: MODEL BAŞARI DEĞERLENDİRME METRİKLERİ (EVALUATION METRICS)
TÜR: Teknik Dokümantasyon ve Performans Analizi

================================================================================
1. GİRİŞ: NEDEN ÖLÇÜM YAPIYORUZ?
================================================================================
Bir makine öğrenmesi modelinin başarısı, "Eğitim Hatası" ile değil, "Test Hatası" ile ölçülür.
Amaç: Modelin veriyi ezberlemediğinden (Overfitting olmadığından) ve genelleştirme yeteneğinin yüksek olduğundan emin olmaktır.

UYARI: Yanlış metriği seçmek, başarısız bir modeli başarılı sanmanıza neden olabilir. (Örn: Dengesiz veri setlerinde Accuracy kullanmak).

================================================================================
2. SINIFLANDIRMA MODELLERİ İÇİN METRİKLER (CLASSIFICATION)
================================================================================
"Evet/Hayır" veya "Kedi/Köpek" gibi kategorik tahminlerin başarısı ölçülür.

A. KARMAŞIKLIK MATRİSİ (CONFUSION MATRIX)
Tüm sınıflandırma metriklerinin temelidir. 4 temel bileşenden oluşur:
1. True Positive (TP): Pozitif dedik, gerçekten Pozitif çıktı. (Doğru bildik)
2. True Negative (TN): Negatif dedik, gerçekten Negatif çıktı. (Doğru bildik)
3. False Positive (FP): Pozitif dedik ama Negatif çıktı. (Yanlış alarm / Tip-1 Hata)
4. False Negative (FN): Negatif dedik ama Pozitif çıktı. (Kaçırdık / Tip-2 Hata)

B. DOĞRULUK (ACCURACY)
- Formül: (TP + TN) / Toplam Veri
- Tanım: Toplam tahminlerin yüzde kaçı doğru?
- Ne Zaman Kullanılır?: Sınıflar dengeli ise (Örn: %50 Kedi, %50 Köpek).
- Tehlike: Kanser verisinde hastaların %99'u sağlıklıysa, model herkese "Sağlıklı" derse %99 Accuracy alır ama kanserlileri bulamaz (Çöp model). Bu durumda kullanılmaz.

C. KESİNLİK (PRECISION)
- Soru: "Pozitif dediğim durumların ne kadarı gerçekten pozitif?"
- Formül: TP / (TP + FP)
- Odak: Yanlış alarm vermemek (FP'yi düşürmek).
- Örnek: Spam filtresi. Normal bir maile "Spam" derseniz (FP), önemli bir iş maili kaybolur. Burada Precision yüksek olmalıdır.

D. DUYARLILIK (RECALL / SENSITIVITY)
- Soru: "Gerçekteki pozitiflerin ne kadarını yakalayabildim?"
- Formül: TP / (TP + FN)
- Odak: Gözden kaçırmamak (FN'i düşürmek).
- Örnek: Kanser tespiti. Hasta olan birine "Sağlıklısın" derseniz (FN) hasta ölebilir. Yanlış alarm vermek (FP) o kadar kötü değildir, tekrar test yapılır. Burada Recall yüksek olmalıdır.

E. F1-SKORU (F1-SCORE)
- Tanım: Precision ve Recall'un harmonik ortalamasıdır.
- Formül: 2 * (Precision * Recall) / (Precision + Recall)
- Ne Zaman Kullanılır?: Dengesiz veri setlerinde (Imbalanced Data) ve hem yanlış alarmın hem de gözden kaçırmanın önemli olduğu durumlarda en güvenilir metriktir.

F. ROC EĞRİSİ VE AUC (AREA UNDER CURVE)
- ROC: Farklı eşik değerleri (Threshold) için başarımı gösteren eğridir.
- AUC: Eğrinin altında kalan alandır. 0 ile 1 arasındadır.
- Yorum: 0.5 (Yazı-Tura) kötüdür, 1.0 mükemmeldir. Sınıf dağılımından bağımsız genel performansı gösterir.

================================================================================
3. REGRESYON MODELLERİ İÇİN METRİKLER (REGRESSION)
================================================================================
Sayısal tahminlerin (Fiyat, Sıcaklık vb.) başarısı ölçülür. Burada "Doğru bildi/Yanlış bildi" yoktur, "Ne kadar yaklaştı?" vardır.

A. ORTALAMA KARE HATA (MSE - MEAN SQUARED ERROR)
- Tanım: Hataların karesinin ortalamasıdır.
- Özellik: Kare alındığı için büyük hataları aşırı cezalandırır.
- Yorum: Modelin büyük sapmalar yapmamasını istiyorsanız bunu kullanın.

B. KÖK ORTALAMA KARE HATA (RMSE - ROOT MEAN SQUARED ERROR)
- Tanım: MSE'nin kareköküdür.
- Özellik: Hedef değişkenle aynı birimdedir (TL ise TL cinsinden). Yorumlaması daha kolaydır. "Ortalama olarak şu kadar TL sapıyoruz" denilebilir.

C. ORTALAMA MUTLAK HATA (MAE - MEAN ABSOLUTE ERROR)
- Tanım: Hataların mutlak değerinin ortalamasıdır.
- Özellik: Aykırı değerlere (Outliers) karşı dirençlidir. MSE gibi büyük hataları abartmaz.

D. R-KARE (R-SQUARED / BELİRLİLİK KATSAYISI)
- Tanım: Bağımsız değişkenlerin, bağımlı değişkendeki değişimi ne kadar açıkladığını gösterir.
- Değer: 0 ile 1 arasındadır (Bazen negatif olabilir ki bu modelin felaket olduğunu gösterir).
- Yorum: 0.80 ise -> Modelimiz, fiyattaki değişimin %80'ini açıklayabiliyor, kalan %20 başka faktörlere bağlı.

================================================================================
4. DOĞRULAMA TEKNİKLERİ (VALIDATION TECHNIQUES)
================================================================================
Metrikleri hangi veri üzerinde hesaplayacağız?

A. Hold-Out Yöntemi (Train/Test Split)
- Veri seti ikiye bölünür: %80 Eğitim, %20 Test.
- Risk: Test seti şans eseri çok kolay veya çok zor verilerden oluşabilir.

B. K-Katlı Çapraz Doğrulama (K-Fold Cross Validation)
- En güvenilir yöntemdir.
- Süreç: Veri 5 eşit parçaya bölünür.
  1. Tur: İlk 4 parça ile eğit, 5. parça ile test et.
  2. Tur: Diğer 4 parça ile eğit, farklı bir parçayla test et.
  ...
- Sonuç: 5 turun ortalaması alınır. Böylece verinin her parçası hem eğitim hem test için kullanılmış olur.

================================================================================
ÖZET TABLO: HANGİ METRİĞİ SEÇMELİYİM?
================================================================================
SENARYO                                  | ÖNERİLEN METRİK
---------------------------------------- | ----------------------
Veri dengeli, genel başarı önemli        | Accuracy
Kanser teşhisi (Kaçırmak ölümcül)        | Recall
Spam filtresi (Yanlış alarm kötü)        | Precision
Veri dengesiz (Fraud vb.)                | F1-Score / AUC
Ev fiyatı tahmini (Büyük hata yapma)     | RMSE
Ev fiyatı (Aykırı değerler çok)          | MAE
Modelin açıklayıcılığı (İstatistiksel)   | R-Squared